<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_dmgt1j38fblk-1>li:before{content:"\0025cb   "}.lst-kix_dmgt1j38fblk-2>li:before{content:"\0025a0   "}.lst-kix_dmgt1j38fblk-3>li:before{content:"\0025cf   "}.lst-kix_dmgt1j38fblk-4>li:before{content:"\0025cb   "}.lst-kix_dmgt1j38fblk-6>li:before{content:"\0025cf   "}.lst-kix_g7mtfsxil7mk-8>li:before{content:"-  "}.lst-kix_nfl3pi2ma7y-5>li:before{content:"\0025a0   "}.lst-kix_nfl3pi2ma7y-4>li:before{content:"\0025cb   "}.lst-kix_dmgt1j38fblk-5>li:before{content:"\0025a0   "}.lst-kix_nfl3pi2ma7y-3>li:before{content:"\0025cf   "}.lst-kix_qhyivxxmbsbh-0>li:before{content:"\0025cf   "}.lst-kix_dmgt1j38fblk-8>li:before{content:"\0025a0   "}.lst-kix_nfl3pi2ma7y-2>li:before{content:"\0025a0   "}.lst-kix_dmgt1j38fblk-7>li:before{content:"\0025cb   "}.lst-kix_g7mtfsxil7mk-2>li:before{content:"-  "}.lst-kix_g7mtfsxil7mk-1>li:before{content:"-  "}.lst-kix_g7mtfsxil7mk-3>li:before{content:"-  "}.lst-kix_g7mtfsxil7mk-0>li:before{content:"-  "}.lst-kix_g7mtfsxil7mk-4>li:before{content:"-  "}.lst-kix_g7mtfsxil7mk-6>li:before{content:"-  "}.lst-kix_g7mtfsxil7mk-5>li:before{content:"-  "}.lst-kix_g7mtfsxil7mk-7>li:before{content:"-  "}.lst-kix_nfl3pi2ma7y-6>li:before{content:"\0025cf   "}ul.lst-kix_qhyivxxmbsbh-1{list-style-type:none}.lst-kix_nfl3pi2ma7y-7>li:before{content:"\0025cb   "}ul.lst-kix_qhyivxxmbsbh-0{list-style-type:none}ul.lst-kix_qhyivxxmbsbh-3{list-style-type:none}ul.lst-kix_qhyivxxmbsbh-2{list-style-type:none}.lst-kix_nfl3pi2ma7y-8>li:before{content:"\0025a0   "}ul.lst-kix_nfl3pi2ma7y-0{list-style-type:none}ul.lst-kix_nfl3pi2ma7y-1{list-style-type:none}ul.lst-kix_qhyivxxmbsbh-8{list-style-type:none}ul.lst-kix_nfl3pi2ma7y-2{list-style-type:none}ul.lst-kix_nfl3pi2ma7y-3{list-style-type:none}.lst-kix_dmgt1j38fblk-0>li:before{content:"\0025cf   "}ul.lst-kix_nfl3pi2ma7y-4{list-style-type:none}ul.lst-kix_qhyivxxmbsbh-5{list-style-type:none}ul.lst-kix_nfl3pi2ma7y-5{list-style-type:none}ul.lst-kix_qhyivxxmbsbh-4{list-style-type:none}ul.lst-kix_nfl3pi2ma7y-6{list-style-type:none}ul.lst-kix_qhyivxxmbsbh-7{list-style-type:none}ul.lst-kix_nfl3pi2ma7y-7{list-style-type:none}ul.lst-kix_qhyivxxmbsbh-6{list-style-type:none}ul.lst-kix_nfl3pi2ma7y-8{list-style-type:none}.lst-kix_s9u4ibgvwlpx-0>li:before{content:"-  "}ul.lst-kix_dmgt1j38fblk-0{list-style-type:none}ul.lst-kix_dmgt1j38fblk-1{list-style-type:none}.lst-kix_s9u4ibgvwlpx-1>li:before{content:"-  "}ul.lst-kix_g7mtfsxil7mk-4{list-style-type:none}ul.lst-kix_g7mtfsxil7mk-3{list-style-type:none}ul.lst-kix_g7mtfsxil7mk-6{list-style-type:none}ul.lst-kix_g7mtfsxil7mk-5{list-style-type:none}ul.lst-kix_g7mtfsxil7mk-8{list-style-type:none}.lst-kix_s9u4ibgvwlpx-6>li:before{content:"-  "}ul.lst-kix_g7mtfsxil7mk-7{list-style-type:none}.lst-kix_s9u4ibgvwlpx-7>li:before{content:"-  "}.lst-kix_s9u4ibgvwlpx-8>li:before{content:"-  "}ul.lst-kix_dmgt1j38fblk-4{list-style-type:none}ul.lst-kix_dmgt1j38fblk-5{list-style-type:none}ul.lst-kix_dmgt1j38fblk-2{list-style-type:none}ul.lst-kix_dmgt1j38fblk-3{list-style-type:none}ul.lst-kix_dmgt1j38fblk-8{list-style-type:none}ul.lst-kix_dmgt1j38fblk-6{list-style-type:none}ul.lst-kix_dmgt1j38fblk-7{list-style-type:none}.lst-kix_qhyivxxmbsbh-3>li:before{content:"\0025cf   "}.lst-kix_qhyivxxmbsbh-2>li:before{content:"\0025a0   "}.lst-kix_qhyivxxmbsbh-4>li:before{content:"\0025cb   "}ul.lst-kix_s9u4ibgvwlpx-7{list-style-type:none}.lst-kix_qhyivxxmbsbh-1>li:before{content:"\0025cb   "}.lst-kix_qhyivxxmbsbh-5>li:before{content:"\0025a0   "}.lst-kix_nfl3pi2ma7y-1>li:before{content:"\0025cb   "}ul.lst-kix_s9u4ibgvwlpx-8{list-style-type:none}.lst-kix_nfl3pi2ma7y-0>li:before{content:"\0025cf   "}ul.lst-kix_g7mtfsxil7mk-0{list-style-type:none}.lst-kix_s9u4ibgvwlpx-5>li:before{content:"-  "}ul.lst-kix_g7mtfsxil7mk-2{list-style-type:none}ul.lst-kix_g7mtfsxil7mk-1{list-style-type:none}ul.lst-kix_s9u4ibgvwlpx-3{list-style-type:none}.lst-kix_qhyivxxmbsbh-7>li:before{content:"\0025cb   "}.lst-kix_s9u4ibgvwlpx-3>li:before{content:"-  "}.lst-kix_s9u4ibgvwlpx-4>li:before{content:"-  "}ul.lst-kix_s9u4ibgvwlpx-4{list-style-type:none}ul.lst-kix_s9u4ibgvwlpx-5{list-style-type:none}.lst-kix_qhyivxxmbsbh-6>li:before{content:"\0025cf   "}.lst-kix_qhyivxxmbsbh-8>li:before{content:"\0025a0   "}ul.lst-kix_s9u4ibgvwlpx-6{list-style-type:none}ul.lst-kix_s9u4ibgvwlpx-0{list-style-type:none}.lst-kix_s9u4ibgvwlpx-2>li:before{content:"-  "}ul.lst-kix_s9u4ibgvwlpx-1{list-style-type:none}ul.lst-kix_s9u4ibgvwlpx-2{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c2{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:10pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Arial";font-style:normal}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c13{padding-top:0pt;padding-bottom:3pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c6{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c9{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c15{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:italic}.c4{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c12{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c16{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c14{color:inherit;text-decoration:inherit}.c11{margin-left:36pt;padding-left:0pt}.c10{padding:0;margin:0}.c3{height:11pt}.c5{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c16"><p class="c13 title" id="h.wa7ncbnay9hq"><span class="c8">Build a Telephone Chatbot with GPT-3 and Twilio Autopilot</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">GPT-3 (Generative Pre-trained Transformer 3) is a highly advanced language model from OpenAI. Its claim to fame is its ability to generate written text that is virtually indistinguishable from human-written text. It&rsquo;s enjoying a ton of buzz these days, so I thought we could have a little fun with it by creating a GPT-3 powered chatbot that you can talk to over the telephone. </span></p><h2 class="c9" id="h.xlhorgtqmkxk"><span class="c7">Technical Requirements</span></h2><p class="c0"><span class="c1">To follow along, you&rsquo;ll need:</span></p><p class="c0 c3"><span class="c1"></span></p><ul class="c10 lst-kix_nfl3pi2ma7y-0 start"><li class="c0 c11"><span>A free Twilio account. If you </span><span class="c12"><a class="c14" href="https://www.google.com/url?q=http://www.twilio.com/referral/p5Zs5e&amp;sa=D&amp;ust=1598891928619000&amp;usg=AOvVaw2PI_VOLtrwSVx_-F-9x-0-">use this link to register</a></span><span class="c1">, you will also receive $10 credit when you upgrade to a paid account.</span></li></ul><ul class="c10 lst-kix_dmgt1j38fblk-0 start"><li class="c0 c11"><span class="c1">An OpenAI API key. Visit openai.com</span></li></ul><h2 class="c9" id="h.hxp1tze1eh5a"><span class="c7">The Goal</span></h2><p class="c0"><span>After completing this tutorial, you&rsquo;ll have a phone number that you can call to have a conversation with a GPT-3 powered chatbot; and hopefully, the process of creating it will have been </span><span>a fun introduction to using Twilio Autopilot, Twilio Functions, and the OpenAI API. </span></p><h2 class="c9" id="h.tn2ppvu8mdcv"><span class="c7">Creating an Autopilot bot</span></h2><p class="c0"><span class="c1">Basically what we&rsquo;re going to do is use Twilio Autopilot as a proxy between our users and GPT-3. So, we&rsquo;ll start by creating an Autopilot bot.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">Log in at twilio.com and navigate to the Autopilot section of the Twilio console. </span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">From there, click the build bot from scratch button. </span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 253.33px;"><img alt="" src="images/image13.png" style="width: 624.00px; height: 253.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span>For the unique name enter </span><span class="c5">gpt3-telephone-bot</span><span>&nbsp;then click the create bot button.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 289.33px;"><img alt="" src="images/image15.png" style="width: 624.00px; height: 289.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">Now you have a super simple Autopilot bot created. At this point the bot is pretty limited but let&rsquo;s test it out using the Autopilot simulator. &nbsp;You&rsquo;ll see a link to the simulator on the left side of the screen. </span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 356.00px;"><img alt="" src="images/image3.png" style="width: 624.00px; height: 356.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">In the simulator, type the word &lsquo;hi&rsquo; and press enter. You should see a response from Autopilot that says &ldquo;Hello, how can I help you today?&rdquo; </span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 454.67px;"><img alt="" src="images/image14.png" style="width: 624.00px; height: 454.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">For now, that&rsquo;s it for the bot set up. Next we&rsquo;ll move on and set up a telephone number that can be used to call the bot.</span></p><h2 class="c9" id="h.txx2f9hane90"><span class="c7">Setting up a phone number for your bot</span></h2><p class="c0"><span class="c1">To configure a Twilio &nbsp;telephone number to work with Autopilot you&rsquo;ll need a voice URL. You can get that from Autopilot by navigating to the channels menu and choosing the programmable voice icon.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 302.67px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 302.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">After clicking the programmable voice icon, copy the voice URL to your clipboard. You&rsquo;ll need this URL to complete the number setup.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 328.00px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 328.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">With the voice URL copied to your clipboard, navigate to the phone numbers menu to buy a number. </span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 338.67px;"><img alt="" src="images/image18.png" style="width: 624.00px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span>From the phone numbers page, </span><span>click the &ldquo;Buy a Number&rdquo; link on the left-side </span><span class="c1">menu. From there, you can search for a number and buy one with the credit provided in your free trial account.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 370.67px;"><img alt="" src="images/image10.png" style="width: 624.00px; height: 370.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">After buying a number, navigate to the Active Numbers menu. Click on the number you purchased to display the settings for your number. Paste the VOICE URL that you previously copied from the Autopilot channel replacing the default Webhook URL (under the setting titled &ldquo;A CALL COMES IN&rdquo;). Then click the save button.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 454.67px;"><img alt="" src="images/image12.png" style="width: 624.00px; height: 454.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">At this point, you should be able to call the number and say &lsquo;hi&rsquo; to hear the default greeting. Give it a try!</span></p><h2 class="c9" id="h.pej891p9b3ln"><span class="c7">Using Twilio functions with Autopilot</span></h2><p class="c0"><span>In Autopilot, &lsquo;tasks&rsquo; are used to associate things users say with actions the bot should take in response. By default, when a new &ldquo;from scratch&rdquo; bot is created, a few tasks are created also. They are the goodbye, greeting, collect_fa</span><span>llback, an</span><span class="c1">d fallback tasks. Each of the default tasks is associated with default actions. For example, the greeting task says &lsquo;Hello, what can I help you with today?&rsquo; and listens for a response. Of course we could change that but for our example we don&rsquo;t need to.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">In most cases, you&rsquo;d create a new task to deal with the different ways a user might respond to a prompt like the one from the greeting task. However, in our case, we want GPT-3 to respond. So, rather than creating new tasks, we&rsquo;re just going to pipe everything to GPT-3 using a Twilio function. </span></p><h3 class="c4" id="h.gdovm5r2o9uo"><span class="c6">Create a Twilio Function</span></h3><p class="c0"><span class="c1">We&rsquo;ll start by creating a blank function. Navigate to the Twilio functions section of the console and click the Create a Function button.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 373.33px;"><img alt="" src="images/image16.png" style="width: 624.00px; height: 373.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">When you are prompted to choose a template, select the blank option.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 406.67px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 406.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">Set the function name to gpt3-telephone-bot.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 457.33px;"><img alt="" src="images/image4.png" style="width: 624.00px; height: 457.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">Set the PATH value to /gpt3-telephone-bot and click save.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 457.33px;"><img alt="" src="images/image9.png" style="width: 624.00px; height: 457.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">Now you need to modify the function code to return a JSON response for Autopilot. You can do that by replacing the default function code with the following code.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">```javascript</span></p><p class="c0"><span class="c1">exports.handler = async (context, event, callback) =&gt; {</span></p><p class="c0"><span class="c1">&nbsp; const response = {};</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; response.actions = await fallbackHandler(event);</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; callback(null, response);</span></p><p class="c0"><span class="c1">};</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">const fallbackHandler = async (event) =&gt; {</span></p><p class="c0"><span class="c1">&nbsp; const actions = [];</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; actions.push({ say: `I heard you say: ${event.CurrentInput}` });</span></p><p class="c0"><span class="c1">&nbsp; actions.push({ listen: true });</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; return actions;</span></p><p class="c0"><span class="c1">};</span></p><p class="c0"><span class="c1">```</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">After replacing the default function code, click the save button and then copy the PATH url for the function to the clipboard.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">The new function code isn&rsquo;t doing much yet. It&rsquo;s just going to echo back the user input but we&rsquo;ll change that later.</span></p><h3 class="c4" id="h.naarr3aveodj"><span class="c6">Set the Autopilot Fallback behavior</span></h3><p class="c0"><span class="c1">The next step is to configure the Autopilot Fallback behavior. The fallback behavior tells Autopilot what to do when it doesn&rsquo;t understand something a user says. By default the fallback task responds by saying: &ldquo;I&#39;m sorry didn&#39;t quite get that. Please say that again.&rdquo; but we&rsquo;re going to change the behavior to call our function code instead.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">From the Tasks list, click on &ldquo;Default Behaviors&rdquo;. </span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 277.33px;"><img alt="" src="images/image8.png" style="width: 624.00px; height: 277.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">Then for the Fallback, change the &ldquo;SEND TO&rdquo; option to &ldquo;Callback URL&rdquo; and paste in the URL for your Twilio Function (it should be saved to your clipboard). Finally, click the save button.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 104.00px;"><img alt="" src="images/image20.png" style="width: 624.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">After changing the Fallback behavior, test with the Autopilot Simulator by saying &lsquo;what is the color of the moon&rsquo;. You should see the function respond with &lsquo;I heard you say: what is the color of the moon&rsquo;.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 495.50px; height: 234.25px;"><img alt="" src="images/image19.png" style="width: 495.50px; height: 234.25px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3"><span class="c1"></span></p><h2 class="c9" id="h.adoy99s040e6"><span class="c7">Understanding the OpenAI API</span></h2><p class="c0"><span class="c1">Alright, now for the fun stuff - integrating GPT-3. But before we dive into the code, let&rsquo;s cover some GPT-3 and OpenAI API basics. For starters, there are three key API core concepts: prompt, completion, and tokens. </span></p><h3 class="c4" id="h.p8fjw6lwh4o"><span class="c6">The prompt and completion</span></h3><p class="c0"><span class="c1">The &ldquo;prompt&rdquo; is the input text sent to the API and the &ldquo;completion&rdquo; is the text the API generates based on the prompt. The prompt, in essence, is the training data that GPT-3 needs to generate the completion. For example, if the prompt was, &ldquo;As Descartes said, I think, therefore&rdquo;, the API will likely return the completion &ldquo; I am&rdquo;. Note that I said &ldquo;the API will likely return&rdquo;. That&rsquo;s because the API is stochastic by default. This means that every time you call it you might get a slightly different completion, even if the prompt doesn&rsquo;t change.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">The following is an example of a prompt and the resulting text generated by GPT-3. The prompt is the bold text and the normal text is what GPT-3 generated.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 368.00px;"><img alt="" src="images/image1.png" style="width: 624.00px; height: 368.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">Pretty cool, right?</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span>NOTE: The example above was done in the OpenAI Playground. In the Playground, you can test and prototype prompts along with other settings that affect how GPT-3 generates completions. We&rsquo;re not going to cover the Playground in this tutorial because we&rsquo;ll be using the API. However, the Playground is a great tool for testing and prototyping GPT-3 prompts. So, I&rsquo;d encourage you to spend time with it. Or, for a deeper dive into the Playground, check out </span><span class="c12"><a class="c14" href="https://www.google.com/url?q=https://www.twilio.com/blog/ultimate-guide-openai-gpt-3-language-model&amp;sa=D&amp;ust=1598891928627000&amp;usg=AOvVaw2ncqANzHr5EXA3FQmwgkN3">The Ultimate Guide to OpenAI&#39;s GPT-3 Language Model</a></span><span class="c1">.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">The API picks up on patterns relatively quickly, so even a single example in the prompt (like in the example above) can be enough to generate a good completion. But adding a few examples usually provides better results. However, adding more than 3-5 examples doesn&rsquo;t necessarily result in a better completion and we&rsquo;re limited on how much text or more accurately how man &ldquo;tokens&rdquo; we have to work with. </span></p><h3 class="c4" id="h.rgh5imudjllk"><span class="c6">Understanding tokens</span></h3><p class="c0"><span class="c1">Tokens are pieces of words that are used to statistically predict the right text for a completion. The API turns our prompt text into tokens before processing it. This lets the API handle more text at one time. For our project, the important thing to note about tokens is that prompt and generated completion together must be below 2048 tokens which is roughly ~1500 words.</span></p><h3 class="c4" id="h.4fw5umbcwrsz"><span class="c6">The Completions endpoint</span></h3><p class="c0"><span class="c1">The OpenAI API just has a few endpoints. The main endpoint is for creating completions. This is the endpoint we&rsquo;ll be using. </span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">```</span></p><p class="c0"><span>POST </span><span>https://api.openai.com/v1/engines/{engine_id}/completions</span></p><p class="c0"><span class="c1">```</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">The Completions endpoint takes in various parameters. However, the only required parameter (which is passed as part of the url) is the engine_id. The engine_id references the underlying model that will be used to generate the completion. </span></p><h3 class="c4" id="h.f3ccdcitqk1x"><span class="c6">Davinci, Curie, Babbage and Ada</span></h3><p class="c0"><span class="c1">Currently four models are available: davinci, curie, babbage and ada. These are the values that can be used for the {engine_id}. The models provide a spectrum of capability, but davinci is the most capable model and the one we&rsquo;ll be using. But if this were a production app, another model might be capable of handling our use-case with less latency. So, if you&rsquo;re building a production app, you&rsquo;ll want to test the other engines.</span></p><h3 class="c4" id="h.jwsx2zdv1juw"><span class="c6">API Request Parameters</span></h3><p class="c0"><span class="c1">As I mentioned, the only required parameter is the engine_id that is passed in the URL path. However, there are a number of other parameters that are important for getting the API to generate the best completion for your application. The following is a list of the available parameters with a brief description of each.</span></p><p class="c0 c3"><span class="c1"></span></p><ul class="c10 lst-kix_qhyivxxmbsbh-0 start"><li class="c2"><span class="c5">prompt:</span><span class="c1">&nbsp;A string or an array of the prompt text</span></li><li class="c2"><span class="c5">max_tokens:</span><span class="c1">&nbsp;An integer that sets the max tokens to generate</span></li><li class="c2"><span class="c5">temperature: </span><span class="c1">A number from 0-1 that determines how much &ldquo;risk&rdquo; the model will take when generating a completion. The higher the value, for example, 0.9, the more &ldquo;creative&rdquo; the completion text will be. NOTE: temperature should not be used if top_p is used.</span></li><li class="c2"><span class="c5">top_p:</span><span class="c1">&nbsp;A number called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. NOTE: top_p should not be used if temperature is used</span></li><li class="c2"><span class="c5">n:</span><span>&nbsp;An </span><span class="c1">integer that specifies the number of completions to generate for each prompt.</span></li><li class="c2"><span class="c5">stream:</span><span class="c1">&nbsp;A boolean value to determine if partial progress should be streamed back.</span></li><li class="c2"><span class="c5">logprobs:</span><span class="c1">&nbsp;An integer that tells the API to include log probabilities on the most likely tokens and chosen tokens.</span></li><li class="c2"><span class="c5">echo:</span><span class="c1">&nbsp;A boolean value that tells the API to ech back the prompt along with the completion</span></li><li class="c2"><span class="c5">stop:</span><span class="c1">&nbsp;A string or array that acts as a delimiter to tell the API will stop generating further tokens. </span></li><li class="c2"><span class="c5">presence_penalty:</span><span class="c1">&nbsp;A number between 0 and 1 (default 0) that penalizes new tokens based on whether they appear in the text so far. This increases the model&#39;s likelihood to talk about new topics.</span></li><li class="c2"><span class="c5">frequency_penalty:</span><span class="c1">&nbsp;A number between 0 and 1 (default 0) that penalizes new tokens based on their existing frequency in the text so far. This decreases the model&#39;s likelihood to repeat the same line verbatim.</span></li><li class="c2"><span class="c5">best_of:</span><span class="c1">&nbsp;An integer that tells the API to only return the &quot;best&quot; of n completions (the one with the lowest log probability per token). If provided, must be greater than n. NOTE: This can&rsquo;t be used if the stream parameter is true.</span></li></ul><p class="c0"><span class="c1">We&rsquo;re not going to be using all of the parameters but we will be using: prompt, max_tokens, temperature, n, stream, logprobs, and stop. So, when we&rsquo;re done, our Twilio function will be passing a request body that looks something like the following example.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">```json</span></p><p class="c0"><span class="c1">{</span></p><p class="c0"><span class="c1">&nbsp; &quot;prompt&quot;: &quot;bot:Hello, how can I help you today?\nhuman:what color is the moon\nbot:&quot;,</span></p><p class="c0"><span class="c1">&nbsp; &quot;max_tokens&quot;: 75,</span></p><p class="c0"><span class="c1">&nbsp; &quot;temperature&quot;: 0.65,</span></p><p class="c0"><span class="c1">&nbsp; &quot;n&quot;: 1,</span></p><p class="c0"><span class="c1">&nbsp; &quot;stream&quot;: false,</span></p><p class="c0"><span class="c1">&nbsp; &quot;logprobs&quot;: null,</span></p><p class="c0"><span class="c1">&nbsp; &quot;stop&quot;: &quot;\n&quot;</span></p><p class="c0"><span class="c1">}</span></p><p class="c0"><span class="c1">```</span></p><h2 class="c9" id="h.wa33tpra6m60"><span class="c7">Calling the OpenAI API from a Twilio Function</span></h2><p class="c0"><span class="c1">Now that we have an understanding of how the OpenAI works and our basic bot wired up, all we need to do is start calling the API. To do that we&rsquo;ll be making HTTP requests that will require an API key. So we&rsquo;ll start there.</span></p><h3 class="c4" id="h.52vj5djavu79"><span class="c6">Finding your OpenAI API Key</span></h3><p class="c0"><span class="c1">Login to the OpenAI developer console and you&rsquo;ll find your API Keys in the Developer Quickstart section of the documentation. Then, copy the &lsquo;Secret&rsquo; key (the one starting with &lsquo;sk-&rsquo;) to your clipboard.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 201.33px;"><img alt="" src="images/image17.png" style="width: 624.00px; height: 201.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3"><span class="c1"></span></p><h3 class="c4" id="h.795fmaybs20p"><span class="c6">Setup your API key as an environment variable</span></h3><p class="c0"><span class="c1">To provide your Twilio function with access to your API key, you&rsquo;ll need to save your secret key as an environment variable. </span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">To do that, navigate to the Function section of the Twilio console and click Configure.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">Then, add an environment variable with the key name OPENAI_API_KEY and paste in your secret as the value.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 370.67px;"><img alt="" src="images/image7.png" style="width: 624.00px; height: 370.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c4" id="h.ssoklro1d60r"><span class="c6">Add the Axios npm module as a dependency</span></h3><p class="c0"><span>In addition to having access to your API key, your function will also need to make HTTP requests to call the API. To make those calls, we&rsquo;ll use the </span><span class="c12"><a class="c14" href="https://www.google.com/url?q=https://www.npmjs.com/package/axios&amp;sa=D&amp;ust=1598891928631000&amp;usg=AOvVaw1_o8G8NhR0_Erw9ReasQza">Axios npm module</a></span><span class="c1">. </span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">To make Axios available to your function code, you&rsquo;ll add it as a dependency. This is also done in the functions configuration.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">Click the &lsquo;plus&rsquo; icon under dependencies then enter the name &lsquo;axios&rsquo; and an asterisk for the version.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 454.67px;"><img alt="" src="images/image6.png" style="width: 624.00px; height: 454.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">Next, save the configuration updates and go back to the Manage action and open your function code.</span></p><h3 class="c4" id="h.u8m4eghonhzz"><span class="c6">Update your function code to call the OpenAI API</span></h3><p class="c0"><span class="c1">With the API key environment variable set and the Axios dependency added we have what we need to start calling the OpenAI API from our function code.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">The changes needed are relatively minor. We&rsquo;ll require the axios module, create an instance of axios, and use the instance to post our prompt text and get a response back.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">The completed code is below. Simply copy the following code and replace the existing code in your Twilio function. Then click save.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">```javascript</span></p><p class="c0"><span class="c1">const axios = require(&#39;axios&#39;);</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">exports.handler = async (context, event, callback) =&gt; {</span></p><p class="c0"><span class="c1">&nbsp; const response = {};</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; response.actions = await fallbackHandler(event);</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; callback(null, response);</span></p><p class="c0"><span class="c1">};</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">const fallbackHandler = async (event) =&gt; {</span></p><p class="c0"><span class="c1">&nbsp; const actions = [];</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; const instance = axios.create({</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; baseURL: &#39;https://api.openai.com/v1/&#39;,</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; headers: { Authorization: `Bearer ${process.env.OPENAI_API_KEY}` },</span></p><p class="c0"><span class="c1">&nbsp; });</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; const dialog = [</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; &#39;bot: Hello, how are you today?&#39;,</span></p><p class="c0"><span class="c1">&nbsp; ];</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; dialog.push(`human: ${event.CurrentInput}`);</span></p><p class="c0"><span class="c1">&nbsp; dialog.push(&#39;bot:&#39;);</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; const completionParmas = {</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; prompt: dialog.join(&#39;\n&#39;),</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; max_tokens: 75,</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; temperature: 0.65,</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; n: 1,</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; stream: false,</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; logprobs: null,</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; echo: false,</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; stop: &#39;\n&#39;,</span></p><p class="c0"><span class="c1">&nbsp; };</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; try {</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; const result = await instance.post(&#39;/engines/davinci/completions&#39;, completionParmas);</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; const botResponse = result.data.choices[0].text.trim();</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; dialog.push(`bot: ${botResponse}`);</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; &nbsp; actions.push({ say: botResponse });</span></p><p class="c0"><span class="c1">&nbsp; } catch (err) {</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; console.log(err);</span></p><p class="c0"><span class="c1">&nbsp; &nbsp; actions.push({ say: &#39;Sorry. Something went wrong.&#39; });</span></p><p class="c0"><span class="c1">&nbsp; }</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">&nbsp; actions.push({ listen: true });</span></p><p class="c0"><span class="c1">&nbsp; return actions;</span></p><p class="c0"><span class="c1">};</span></p><p class="c0"><span class="c1">```</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">That&rsquo;s it! Your GPT-3 powered telephone chatbot is complete. Give your Twilio number a call and try it out. </span></p><h2 class="c9" id="h.aw605418t69p"><span class="c7">Conclusion and next steps</span></h2><p class="c0"><span class="c1">Hopefully, you had some fun with this tutorial and learned some things in the process.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">For next steps, you might want to dabble with the request parameters to see how they affect the responses you get back from the API. For example, try adjusting the temperature. If you recall, the higher it is, the more &ldquo;creative&rdquo; the responses will be. Or, include a presence_penalty value and the bot might take the conversation in interesting new directions.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c1">You could also easily set up your bot to work with SMS. Just follow the steps you completed for setting up the Autopilot programmable voice channel but copy the messaging url from the programmable messaging channel and use it as the webhook for your Twilio telephone number.</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span>So dabble on, have some fun, and me us know what you </span><span>create</span><span>!</span></p><p class="c0 c3"><span class="c1"></span></p><p class="c0"><span class="c15">Steve Tingiris is a Twilio Champion and the founder of Dabble Lab, a Twilio Partner that specializes in building natural language understanding and automation solutions for enterprise and contact center applications. Reach out to him at steve [at] dabblelab [dot] com.</span></p></body></html>